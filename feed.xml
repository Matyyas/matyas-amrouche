<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="https://github.com/Matyyas/matyas-amrouche.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://github.com/Matyyas/matyas-amrouche.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2022-10-31T12:26:36+00:00</updated><id>https://github.com/Matyyas/matyas-amrouche.github.io/feed.xml</id><title type="html">blank</title><subtitle>My personal website. </subtitle><entry><title type="html">A Journey into Deep Reinforcement Learning</title><link href="https://github.com/Matyyas/matyas-amrouche.github.io/blog/2022/a-journey-into-deep-reinforcement-learning/" rel="alternate" type="text/html" title="A Journey into Deep Reinforcement Learning"/><published>2022-05-27T15:24:26+00:00</published><updated>2022-05-27T15:24:26+00:00</updated><id>https://github.com/Matyyas/matyas-amrouche.github.io/blog/2022/a-journey-into-deep-reinforcement-learning</id><content type="html" xml:base="https://github.com/Matyyas/matyas-amrouche.github.io/blog/2022/a-journey-into-deep-reinforcement-learning/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Deep Q-Network explainedContinue reading on Towards Data Science »]]></summary></entry><entry><title type="html">Principal Component Analysis explained</title><link href="https://github.com/Matyyas/matyas-amrouche.github.io/blog/2020/principal-component-analysis-explained/" rel="alternate" type="text/html" title="Principal Component Analysis explained"/><published>2020-08-16T22:50:54+00:00</published><updated>2020-08-16T22:50:54+00:00</updated><id>https://github.com/Matyyas/matyas-amrouche.github.io/blog/2020/principal-component-analysis-explained</id><content type="html" xml:base="https://github.com/Matyyas/matyas-amrouche.github.io/blog/2020/principal-component-analysis-explained/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Some algebra to understand why PCA works &#x1F527;Continue reading on Towards Data Science »]]></summary></entry><entry><title type="html">Tips to deploy python package on AWS Lambda</title><link href="https://github.com/Matyyas/matyas-amrouche.github.io/blog/2020/tips-to-deploy-python-package-on-aws-lambda/" rel="alternate" type="text/html" title="Tips to deploy python package on AWS Lambda"/><published>2020-06-05T13:05:16+00:00</published><updated>2020-06-05T13:05:16+00:00</updated><id>https://github.com/Matyyas/matyas-amrouche.github.io/blog/2020/tips-to-deploy-python-package-on-aws-lambda</id><content type="html" xml:base="https://github.com/Matyyas/matyas-amrouche.github.io/blog/2020/tips-to-deploy-python-package-on-aws-lambda/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[And keep your git clean!Continue reading on The Startup »]]></summary></entry><entry><title type="html">Playing cards with Reinforcement Learning</title><link href="https://github.com/Matyyas/matyas-amrouche.github.io/blog/2020/playing-cards-with-reinforcement-learning/" rel="alternate" type="text/html" title="Playing cards with Reinforcement Learning"/><published>2020-05-17T21:58:06+00:00</published><updated>2020-05-17T21:58:06+00:00</updated><id>https://github.com/Matyyas/matyas-amrouche.github.io/blog/2020/playing-cards-with-reinforcement-learning</id><content type="html" xml:base="https://github.com/Matyyas/matyas-amrouche.github.io/blog/2020/playing-cards-with-reinforcement-learning/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Concepts &amp; Python Code &#x1F40D;Continue reading on Towards Data Science »]]></summary></entry><entry><title type="html">Short Text Topic Modeling</title><link href="https://github.com/Matyyas/matyas-amrouche.github.io/blog/2019/short-text-topic-modeling/" rel="alternate" type="text/html" title="Short Text Topic Modeling"/><published>2019-08-22T20:56:00+00:00</published><updated>2019-08-22T20:56:00+00:00</updated><id>https://github.com/Matyyas/matyas-amrouche.github.io/blog/2019/short-text-topic-modeling</id><content type="html" xml:base="https://github.com/Matyyas/matyas-amrouche.github.io/blog/2019/short-text-topic-modeling/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Intuition and (some) maths to understand Topic Modeling on short textsContinue reading on Towards Data Science »]]></summary></entry><entry><title type="html">Word Embedding (Part II) : Intuition and (some) maths to understand end-to-end GloVe model</title><link href="https://github.com/Matyyas/matyas-amrouche.github.io/blog/2019/word-embedding-part-ii-intuition-and-some-maths-to-understand-end-to-end-glove-model/" rel="alternate" type="text/html" title="Word Embedding (Part II) : Intuition and (some) maths to understand end-to-end GloVe model"/><published>2019-04-26T07:37:05+00:00</published><updated>2019-04-26T07:37:05+00:00</updated><id>https://github.com/Matyyas/matyas-amrouche.github.io/blog/2019/word-embedding-part-ii-intuition-and-some-maths-to-understand-end-to-end-glove-model</id><content type="html" xml:base="https://github.com/Matyyas/matyas-amrouche.github.io/blog/2019/word-embedding-part-ii-intuition-and-some-maths-to-understand-end-to-end-glove-model/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[The original issue of NLP (Natural Language Processing) is the encoding of a word/sentence into an understandable format for computer&#x2026;Continue reading on Towards Data Science »]]></summary></entry><entry><title type="html">Word Embeddings : Intuition and (some) maths to understand end-to-end Skip-gram model</title><link href="https://github.com/Matyyas/matyas-amrouche.github.io/blog/2019/word-embeddings-intuition-and-some-maths-to-understand-end-to-end-skip-gram-model/" rel="alternate" type="text/html" title="Word Embeddings : Intuition and (some) maths to understand end-to-end Skip-gram model"/><published>2019-02-27T11:26:12+00:00</published><updated>2019-02-27T11:26:12+00:00</updated><id>https://github.com/Matyyas/matyas-amrouche.github.io/blog/2019/word-embeddings-intuition-and-some-maths-to-understand-end-to-end-skip-gram-model</id><content type="html" xml:base="https://github.com/Matyyas/matyas-amrouche.github.io/blog/2019/word-embeddings-intuition-and-some-maths-to-understand-end-to-end-skip-gram-model/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[The original issue of NLP is the encoding of a word/sentence into an understandable format for computer processing. Representation of&#x2026;Continue reading on Towards Data Science »]]></summary></entry></feed>